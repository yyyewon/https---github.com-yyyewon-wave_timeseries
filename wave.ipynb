{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   time  wave_elevation\n",
            "0   0.4       -0.805473\n",
            "1   0.5       -0.887687\n",
            "2   0.6       -0.932218\n",
            "3   0.7       -0.935635\n",
            "4   0.8       -0.899018\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/yewon/anaconda3/lib/python3.11/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30, Loss: 0.052890\n",
            "Epoch 2/30, Loss: 0.039939\n",
            "Epoch 3/30, Loss: 0.035576\n",
            "Epoch 4/30, Loss: 0.036042\n",
            "Epoch 5/30, Loss: 0.034826\n",
            "Epoch 6/30, Loss: 0.034580\n",
            "Epoch 7/30, Loss: 0.033867\n",
            "Epoch 8/30, Loss: 0.033433\n",
            "Epoch 9/30, Loss: 0.033332\n",
            "Epoch 10/30, Loss: 0.033184\n",
            "Epoch 11/30, Loss: 0.032522\n",
            "Epoch 12/30, Loss: 0.032850\n",
            "Epoch 13/30, Loss: 0.032607\n",
            "Epoch 14/30, Loss: 0.032540\n",
            "Epoch 15/30, Loss: 0.032249\n",
            "Epoch 16/30, Loss: 0.031908\n",
            "Epoch 17/30, Loss: 0.032193\n",
            "Epoch 18/30, Loss: 0.032048\n",
            "Epoch 19/30, Loss: 0.031753\n",
            "Epoch 20/30, Loss: 0.031864\n",
            "Epoch 21/30, Loss: 0.031807\n",
            "Epoch 22/30, Loss: 0.031757\n",
            "Epoch 23/30, Loss: 0.031546\n",
            "Epoch 24/30, Loss: 0.031777\n",
            "Epoch 25/30, Loss: 0.031444\n",
            "Epoch 26/30, Loss: 0.031387\n",
            "Epoch 27/30, Loss: 0.031034\n",
            "Epoch 28/30, Loss: 0.031327\n",
            "Epoch 29/30, Loss: 0.031191\n",
            "Epoch 30/30, Loss: 0.031097\n",
            "Training complete.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 파일 경로\n",
        "file_path = \"LIN_001_IRR_WAVE.ele\"\n",
        "\n",
        "# 파일 읽기\n",
        "with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# 첫 번째 줄: TITLE (무시)\n",
        "# 두 번째 줄: 열 이름 (변수명 포함)\n",
        "header = lines[1].strip().replace('\"', '').split(\", \")\n",
        "\n",
        "# 데이터 부분 (2번째 줄 이후)\n",
        "data = [line.strip().split() for line in lines[2:]]\n",
        "\n",
        "# 데이터프레임 생성\n",
        "df = pd.DataFrame(data, columns=[\"time\", \"wave_elevation\"])\n",
        "\n",
        "# 데이터 타입 변환 (문자열 -> float)\n",
        "df[\"time\"] = df[\"time\"].astype(float)\n",
        "df[\"wave_elevation\"] = df[\"wave_elevation\"].astype(float)\n",
        "\n",
        "# 데이터 확인\n",
        "print(df.head())\n",
        "\n",
        "# 데이터프레임 저장 (선택 사항)\n",
        "df.to_csv(\"wave_elevation.csv\", index=False)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "sequence_length = 10  # 입력 시퀀스 길이\n",
        "batch_size = 32\n",
        "epochs = 30\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "# 데이터셋 클래스 정의\n",
        "class TimeSeriesDataset(Dataset):\n",
        "    def __init__(self, data, sequence_length):\n",
        "        self.data = data\n",
        "        self.sequence_length = sequence_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.sequence_length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.data[idx:idx + self.sequence_length]\n",
        "        y = self.data[idx + self.sequence_length]\n",
        "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "\n",
        "# 데이터 준비\n",
        "data_values = df[\"wave_elevation\"].values\n",
        "dataset = TimeSeriesDataset(data_values, sequence_length)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "# 트랜스포머 모델 정의\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, input_dim, model_dim, num_heads, num_layers, dropout=0.1):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.embedding = nn.Linear(input_dim, model_dim)\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=model_dim, nhead=num_heads, dropout=dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
        "        self.fc = nn.Linear(model_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x.unsqueeze(-1))  # (batch, seq_len, model_dim)\n",
        "        x = self.transformer_encoder(x)\n",
        "        x = self.fc(x[:, -1, :])  # 마지막 타임스텝만 예측\n",
        "        return x.squeeze(-1)\n",
        "\n",
        "\n",
        "# 모델 생성\n",
        "input_dim = 1\n",
        "model_dim = 64\n",
        "num_heads = 4\n",
        "num_layers = 2\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = TransformerModel(input_dim, model_dim, num_heads, num_layers).to(device)\n",
        "\n",
        "# 손실 함수 및 옵티마이저 정의\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 모델 학습\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in dataloader:\n",
        "        x_batch, y_batch = batch\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x_batch)\n",
        "        loss = criterion(output, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(dataloader):.6f}\")\n",
        "\n",
        "print(\"Training complete.\")"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
